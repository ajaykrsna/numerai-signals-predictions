{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 1. Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Install and import dependies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numerapi==2.3.8\n",
    "#!pip install yfinance\n",
    "#!pip install simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numerapi\n",
    "import yfinance\n",
    "import simplejson\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import requests as re \n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta, FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "source": [
    "### Numerapi and Signals tickers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAPI_PUBLIC_KEY = '276T6FPFGSKDOT2STIHYDFYZQ67IBBMU'\n",
    "NAPI_PRIVATE_KEY = 'NEQ33QL63TEST6EK4YQLFRGF4257MK4POPOEGJRGZOYERVJ6C3K2GLUOFPKYF6GM'\n",
    "napi = numerapi.SignalsAPI(NAPI_PUBLIC_KEY, NAPI_PRIVATE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of eligble tickers : 5412\n"
     ]
    }
   ],
   "source": [
    "# read in list of active Signals tickers which can change slightly era to era\n",
    "eligible_tickers = pd.Series(napi.ticker_universe(), name = 'ticker')\n",
    "print(f\"Number of eligble tickers : {len(eligible_tickers)}\")"
   ]
  },
  {
   "source": [
    "# read in yahoo to numerai ticker map, still a work in progress, h/t wsouza and\n",
    "# this tickermap is a work in progress and not guaranteed to be 100% correct \n",
    "ticker_map = pd.read_csv('https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_ticker_map_w_bbg.csv')\n",
    "ticker_map = ticker_map[ticker_map.bloomberg_ticker.isin(eligible_tickers)]\n",
    "\n",
    "numerai_tickers = ticker_map['bloomberg_ticker']\n",
    "yfinance_tickers = ticker_map['yahoo']\n",
    "print(f\"Number of eligible tickers in map: {len(ticker_map)}\")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of eligible tickers in map: 5411\n"
     ]
    }
   ]
  },
  {
   "source": [
    "### YFinance price feed download\n",
    "Download price data (adjusted close) using Yahoo Finance Wrapper"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 600 #chunk row size\n",
    "chunk_df = [yfinance_tickers.iloc[i:i+n] for i in range(0, len(yfinance_tickers), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[*********************100%***********************]  599 of 599 completed\n",
      "[*********************100%***********************]  600 of 600 completed\n",
      "[*********************100%***********************]  594 of 594 completed\n",
      "[*********************100%***********************]  594 of 594 completed\n",
      "[*********************100%***********************]  595 of 595 completed\n",
      "[*********************100%***********************]  588 of 588 completed\n",
      "[*********************100%***********************]  591 of 591 completed\n",
      "[*********************100%***********************]  594 of 594 completed\n",
      "[*********************100%***********************]  595 of 595 completed\n",
      "[*********************100%***********************]  11 of 11 completed\n"
     ]
    }
   ],
   "source": [
    "concat_dfs = []\n",
    "for df in chunk_df:\n",
    "    try:\n",
    "        # set_threads = True for faster performance, but tickers will fail, script may hang\n",
    "        # set_threads = False for slower performance, but more tickers will succeed\n",
    "        temp_df = yfinance.download(df.str.cat(sep=' '), start='2002-12-01', threads=False)\n",
    "        temp_df = temp_df['Adj Close'].stack().reset_index()\n",
    "    except simplejson.errors.JSONDecodeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.concat(concat_dfs)"
   ]
  },
  {
   "source": [
    "## 2. Data wrangle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properly position and clean raw data, after taking adjusted close only\n",
    "full_data.columns = ['date', 'ticker', 'price']\n",
    "full_data.set_index('date', inplace=True)\n",
    "\n",
    "# convert yahoo finace tickers back to numerai tickers\n",
    "full_data['ticker'] = full_data.ticker.map(dict(zip(yfinance_tickers, numerai_tickers)))\n",
    "\n",
    "print(f\"Number of tickers with data: {len(full_data.ticker.unique())}\")\n",
    "full_data.head()"
   ]
  },
  {
   "source": [
    "### Engineer features\n",
    "Now that we've downloaded the raw price data, we need to set up features we want to predict the target. For this example, we'll use RSI, which is a technical indicator that attempts to measure how \"oversold\" or \"overbought\" a stock is. A good rule of thumb is that an RSI > 70 indicates a stock is overbought and an RSI < 30 is oversold."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSI(prices, interval=14):\n",
    "    '''Computes Relative Strength Index given a price series and \n",
    "    lookback interval'''\n",
    "    delta = prices.diff()\n",
    "\n",
    "    dUp, dDown = delta.copy(), delta.copy()\n",
    "    dUp[dUp < 0] = 0\n",
    "    dDown[dDown >] = 0\n",
    "\n",
    "    RollUp =dUp.rolling(interval).mean()\n",
    "    RollDown = dDown.rolling(interval).mean.abs()\n",
    "\n",
    "    RS = RollUp / RollDown\n",
    "    RSI = 100.0 - (100.0 / (1.0 + RS))\n",
    "    return RSI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_groups = full_data.groupby('ticker')\n",
    "full_data['RSI'] = ticker_groups['price'].transform(lambda x: RSI(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by era (date) and create quintile labels within each era, useful for learning relative ranking \n",
    "date_groups = full_data.groupby(full_data.index)\n",
    "full_data['RSI_quintile'] = date_groups['RSI'].transform(lambda group: pd.qcut(group, 5, labels=False, duplicates='drop'))\n",
    "full_data.dropna(inplace=True)\n",
    "\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_groups = full_data('ticker')\n",
    "\n",
    "# create lagged features, lag 0 is that day's value, lag 1 is yesterday's value, etc\n",
    "num_days = 5\n",
    "for day in range(num_days+1):\n",
    "    full_data[f'RSI_quintile_lag_{day}'] = ticker_groups['RSI_quintile'].transform(lambda group: group.shift(day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create difference of the lagged fetures (change RSI quintile by day)\n",
    "for day in range(num_days):\n",
    "    full_data[f'RSI_diff_{day}'] = full_data[f'RSI_quintile_lag_{day}'] - full_data[f'RSI_quintile_lag_{day + 1}']\n",
    "    full_data[f'RSI_abs_diff_{day}'] = np.abs(full_data[f'RSI_quintile_lag_{day}'] - full_data[f'RSI_quintile_lag_{day + 1}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [f'RSI_quintile_lag_{num}' for num in range(num_days)] + [f'RSI_diff_{num}' for num in range(num_days)] + [f'RSI_abs_diff_{num}' for num in range(num_days)]\n",
    "print(f'Features for training:\\n (feature_names)')"
   ]
  },
  {
   "source": [
    "### Targets \n",
    "Every era will begin on a Friday, ignore first two days of return (i.e. Monday, Tuesday) and then be based on the subsequent 4 days of return (i.e. Tuesday Close to Monday Close). The targets take on values of {0, 0.25, 0.5, 0.75, 1}, but they are not balanced classes.\n",
    "\n",
    "Try to think of the targets as normalized and neutralized rankings of returns within each era. 10% of the values take on 0 or 1, 40% of the values take on 0.25 or 0.75 and 50% of the values take on 0.5."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_NAME = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}